# Multi-Arm Bandits using Thompson Sampling and Probabilistic Matrix Factorization

Final project for *Advanced Machine Learning for Personalization (COMS6998), Columbia Spring 2018*. We explore the Particle Thompson Sampling with Probabilistic Matrix-Factorization for ratings-based recommender systems.

At the base of this repository we have `Online Recommendation via Particle Thompson Sampling.ipynb` which contains an implementation of the algorithm and some simple analysis. A description of the subfolders follows.

1. analysis - this is our sandbox and we make no guarantees that these notebooks will run at first attempt
1. report - source latex for our report
1. results - binary data used in creating analysis for our report

### References:
##### [1] Efficient Thompson Sampling for Online Matrix-Factorization Recommendation (Kawale et. al., 2015)
##### [2] Online Interactive Collaborative Filtering Using Multi-Armed Bandit with Dependent Arms (Wang et. al., 2017)
##### [3] Interactive Collaborative Filtering (Zhao et. al., 2013)
##### [4] Learning to Optimize Via Posterior Sampling (Daniel Russo, Benjamin Roy. 2014)
##### [5] Sequential Monte Carlo Bandits (Michael Cherkassky, Luke Bornn. 2013)
##### [6] Analysis of Thompson Sampling for the Multi-armed Bandit Problem (Agrawal, Goyal 2012)
##### [7] A Tutorial on Thompson Sampling (Russo, et. al 2018)

### Team: 
#### Michael Alvarino, Bharat Srikishan, Colby Wise @Columbia.edu 

### Keywords: 
##### Particle Filtering, Thompson Sampling, Probabilistic Matrix Factorization, Bayesian Hierarchical Multi-Arm Bandits


