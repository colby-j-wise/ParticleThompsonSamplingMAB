{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import invgamma\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"data/ml-100k/u1.base\"\n",
    "with open(filePath, \"rt\") as dataPath:\n",
    "    raw_data = dataPath.read().splitlines()\n",
    "datapoints = [[int(i) for i in data.split(\"\\t\")] for data in raw_data]\n",
    "\n",
    "# indexing on users/movies starts at 1, reset to index from 0, this will be important when we do testing\n",
    "datapoints = [[row[0] - 1, row[1] - 1, row[2], row[3]] for row in datapoints]\n",
    "\n",
    "user_ids = set([datapoint[0] for datapoint in datapoints])\n",
    "items_ids = set([datapoint[1] for datapoint in datapoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = {user_id: {} for user_id in user_ids}\n",
    "for user_id, item_id, rating, timestamp in datapoints:\n",
    "    user_ratings[user_id][item_id] = (rating, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ratings = {item_id: {} for item_id in items_ids}\n",
    "for user_id, item_id, rating, timestamp in datapoints:\n",
    "    item_ratings[item_id][user_id] = (rating, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(var, v_j, var_u, k):\n",
    "    first = 1 / var * np.dot(v_j, v_j.T)\n",
    "    second = 1 / var_u * np.eye(k)\n",
    "    if v_j.shape[1] > 0:\n",
    "        return first * second\n",
    "    return second\n",
    "\n",
    "def eta(r_ij, v_j, k):\n",
    "    return np.sum(np.array(v_j) * np.array(r_ij), axis=1)\n",
    "    \n",
    "def mu(var, prec, et):\n",
    "    if np.array_equal(prec, np.zeros(prec.shape)):\n",
    "        return np.zeros(prec.shape[0])\n",
    "    return np.dot(1 / var * np.linalg.inv(prec), et)\n",
    "    \n",
    "def SampleUi(r_ij, v_j, var_u, var, k):\n",
    "    prec = precision(var, v_j, var_u, k)\n",
    "    et = eta(r_ij, v_j, k)\n",
    "    m = mu(var, prec, et)\n",
    "    return np.random.multivariate_normal(m, prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # subtract max value to prevent overflow\n",
    "    return np.exp(x - np.max(x)) / np.sum(np.exp(x - np.max(x)))\n",
    "#     s = np.sum([np.exp(i) for i in numpy_arr])\n",
    "#     return np.array([np.exp(i) / s for i in numpy_arr]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_resample(weights):\n",
    "    N = len(weights)\n",
    "    # make N subdivisions, and chose a random position within each one\n",
    "    positions = (np.random.random(N) + range(N)) / N\n",
    "\n",
    "    indexes = np.zeros(N, 'i')\n",
    "    cumulative_sum = np.cumsum(weights)\n",
    "    i, j = 0, 0\n",
    "    while i < N:\n",
    "        if positions[i] < cumulative_sum[j]:\n",
    "            indexes[i] = j\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def systematic_resample(weights):\n",
    "    N = len(weights)\n",
    "\n",
    "    # make N subdivisions, and choose positions with a consistent random offset\n",
    "    positions = (np.random.random_sample() + np.arange(N)) / N\n",
    "\n",
    "    indexes = np.zeros(N, 'i')\n",
    "    cumulative_sum = np.cumsum(weights)\n",
    "    i, j = 0, 0\n",
    "    while i < N:\n",
    "        if positions[i] < cumulative_sum[j]:\n",
    "            indexes[i] = j\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_var(matrix, alpha, beta, k, n_users):\n",
    "    alpha = n_users * k / 2.0 + alpha\n",
    "    beta = 0.5 * np.linalg.norm(matrix, 'fro') + beta\n",
    "    # Generate random value from inverse gamma(shape,scale)\n",
    "    var = invgamma.rvs(alpha, scale=beta)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current regret:  0\n",
      "current regret:  808\n",
      "current regret:  1637\n",
      "current regret:  2527\n",
      "current regret:  3369\n",
      "current regret:  4252\n",
      "current regret:  5023\n",
      "current regret:  5885\n",
      "current regret:  6762\n",
      "current regret:  7700\n",
      "current regret:  8632\n",
      "current regret:  9489\n",
      "current regret:  10345\n",
      "current regret:  11257\n",
      "current regret:  12117\n",
      "current regret:  12964\n",
      "current regret:  13760\n",
      "current regret:  14633\n",
      "current regret:  15377\n",
      "current regret:  16273\n",
      "current regret:  17165\n",
      "current regret:  18019\n",
      "current regret:  18860\n",
      "current regret:  19710\n",
      "current regret:  20600\n",
      "current regret:  21421\n",
      "current regret:  22210\n",
      "current regret:  22992\n",
      "current regret:  23741\n",
      "current regret:  24526\n",
      "current regret:  25283\n",
      "current regret:  25935\n",
      "current regret:  26665\n",
      "current regret:  27493\n",
      "current regret:  28244\n",
      "current regret:  29021\n",
      "current regret:  29859\n",
      "current regret:  30642\n",
      "current regret:  31453\n",
      "current regret:  32271\n",
      "current regret:  33094\n",
      "current regret:  33771\n",
      "current regret:  34584\n",
      "current regret:  35391\n",
      "current regret:  36226\n",
      "current regret:  37104\n",
      "current regret:  37884\n",
      "current regret:  38717\n",
      "current regret:  39600\n",
      "current regret:  40477\n",
      "current regret:  41384\n",
      "current regret:  42119\n",
      "current regret:  42900\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1650 is out of bounds for axis 1 with size 1650",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-128769410883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mlambdas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_over_sig_sqr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mv_js\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"v\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"movies_seen\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mlambdas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_js\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_js\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1650 is out of bounds for axis 1 with size 1650"
     ]
    }
   ],
   "source": [
    "var = 1.0\n",
    "var_u = 1.0\n",
    "var_v = 1.0\n",
    "k = 3\n",
    "n_particles = 5\n",
    "alpha = 2\n",
    "beta = 0.5\n",
    "\n",
    "tot_reward = 0\n",
    "\n",
    "particles = [{\"u\": np.random.normal(size=(len(user_ids), k)),\n",
    "              \"v\": np.random.normal(size=(k, len(items_ids))),\n",
    "              \"var_u\": 1.0,\n",
    "              \"var_v\": 1.0,\n",
    "              \"w\": 1 / n_particles} for particle in range(n_particles)]\n",
    "\n",
    "# user_ratings_seen = {}\n",
    "users = {}\n",
    "items = {}\n",
    "\n",
    "for _idx, (user_id, item_id, rating, timestamp) in enumerate(datapoints):\n",
    "    \n",
    "    if user_id not in users:\n",
    "        users[user_id] = {\"movies_seen\": [], \"rewards\": []}\n",
    "    user_data = users[user_id]\n",
    "        \n",
    "    particle_ind = np.random.choice(range(n_particles), p=[x[\"w\"] for x in particles])\n",
    "    \n",
    "    v_tilde = particles[particle_ind][\"v\"]\n",
    "    \n",
    "    v_j = v_tilde[:, user_data[\"movies_seen\"]]\n",
    "    \n",
    "    r_ij = user_data[\"rewards\"]\n",
    "    \n",
    "    u_i = SampleUi(r_ij, v_j, particles[particle_ind][\"var_u\"], var, k)\n",
    "    \n",
    "    pred = np.dot(u_i, v_j)\n",
    "    \n",
    "    try:\n",
    "        j = np.argmax(pred)\n",
    "    except:\n",
    "        # if argmax fails, it's because u_i and v_j hav no data yet, just suggest something at random\n",
    "        j = np.random.randint(len(items_ids))\n",
    "    \n",
    "    \n",
    "    if j in user_ratings[user_id] and user_ratings[user_id][j][0] > 2.5:\n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = 0\n",
    "        \n",
    "    tot_reward += reward\n",
    "    \n",
    "    if _idx % 1001 == 0:\n",
    "        print(\"current regret: \", _idx - tot_reward)\n",
    "        \n",
    "    users[user_id][\"rewards\"].append(reward)\n",
    "    users[user_id][\"movies_seen\"].append(item_id)\n",
    "    \n",
    "    try:\n",
    "        items[j][\"rewards\"].append(reward)\n",
    "        items[j][\"users_seen\"].append(user_id)\n",
    "    except:\n",
    "        items[j] = {\"rewards\": [reward], \"users_seen\": [user_id]}\n",
    "    \n",
    "    # update posterior\n",
    "    lambdas = []\n",
    "    for particle in particles:\n",
    "        one_over_sig_sqr = np.eye(k) * 1 / particle[\"var_u\"]\n",
    "        if len(user_data[\"movies_seen\"]) == 0:\n",
    "            lambdas.append(one_over_sig_sqr)\n",
    "        else:\n",
    "            v_js = particle[\"v\"][:, user_data[\"movies_seen\"]]\n",
    "            lambdas.append(np.dot(v_js, v_js.T) * 1 / var)\n",
    "        \n",
    "    etas = []\n",
    "    movies_seen = user_data[\"movies_seen\"]\n",
    "    for particle in particles:\n",
    "        # first movie for this user, eta should be zero\n",
    "        if len(movies_seen) == 0:\n",
    "            etas.append(np.zeros(k))\n",
    "        else:\n",
    "            e = eta(r_ij, particle[\"v\"][:, movies_seen], k)\n",
    "            etas.append(e)\n",
    "    \n",
    "    weights = []\n",
    "    for idx, particle in enumerate(particles):\n",
    "        try:\n",
    "            loc = np.dot(particle[\"v\"][:, j], mu(var, lambdas[idx], etas[idx]))\n",
    "        except:\n",
    "            loc = np.zeros(1)\n",
    "        scale = 1 / var * np.dot(np.dot(particle[\"v\"][:, j].T, lambdas[idx]), particle[\"v\"][:, j])\n",
    "        weights.append(np.random.normal(loc, scale))\n",
    "    \n",
    "    weights = softmax(normalize(np.array(weights).reshape(-1, 1)))\n",
    "    \n",
    "    particle_indices = systematic_resample(weights)\n",
    "    \n",
    "    new_particles = []\n",
    "    for ind in particle_indices:\n",
    "        particle = particles[ind]\n",
    "        new_particles.append({\n",
    "            \"u\": particle[\"u\"],\n",
    "            \"v\": particle[\"v\"],\n",
    "            \"var_u\": particle[\"var_u\"],\n",
    "            \"var_v\": particle[\"var_v\"],\n",
    "            \"w\": 1 / n_particles,\n",
    "            \"lambda\": lambdas[ind],\n",
    "            \"eta\": etas[ind]\n",
    "        })\n",
    "    particles = new_particles\n",
    "    \n",
    "    for particle in particles:\n",
    "        lambda_upd = 1 / var * np.dot(v_tilde[:, j].reshape(-1, 1), v_tilde[:, j].reshape(1, -1))\n",
    "        particle[\"lambda\"] += lambda_upd\n",
    "        eta_update = reward * v_tilde[:, j]\n",
    "        particle[\"eta\"] += eta_update\n",
    "        u_i = SampleUi(users[user_id][\"rewards\"],\n",
    "                       particle[\"v\"][:, user_data[\"movies_seen\"]],\n",
    "                       particle[\"var_u\"],\n",
    "                       var,\n",
    "                       k)\n",
    "        particle[\"u\"][user_id, :] = u_i\n",
    "        u_ij = particle[\"u\"][items[j][\"users_seen\"], :]\n",
    "        prec_v = np.dot(u_ij.T, u_ij) + 1 / particle[\"var_v\"] * np.eye(k)\n",
    "        et = np.dot(u_ij.T, np.array(items[j][\"rewards\"]))\n",
    "        v_j = np.random.multivariate_normal(var * np.dot(np.linalg.inv(prec_v), et), np.linalg.inv(prec_v))\n",
    "        particle[\"v\"][:, j] = v_j\n",
    "        particle[\"var_u\"] = sample_var(particle[\"u\"], alpha, beta, k, len(user_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
